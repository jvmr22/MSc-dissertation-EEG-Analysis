{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treino completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from model import DGCNN\n",
    "from sklearn import preprocessing\n",
    "from utils import generating_data\n",
    "from glob import glob\n",
    "\n",
    "lr_dgcnn = 0.01\n",
    "weight_decay_dgcnn = 5e-4 #tem no codigo do GMSS tmbm\n",
    "K=2\n",
    "epochs=20 # DEFFERARD TMBM USA 20\n",
    "device = 'cpu'\n",
    "\n",
    "hiperparam_run = {\n",
    "    'lr_dgcnn ':lr_dgcnn,\n",
    "    'weight_decay_dgcnn':weight_decay_dgcnn,\n",
    "    'K':K,\n",
    "    'epochs':epochs\n",
    "}\n",
    "\n",
    "label_list = np.array([1,0,-1,-1,0,1,-1,0,1,1,0,-1,0,1,-1]) + 1 # -1 for \n",
    "fn = 'de_LDS'\n",
    "\n",
    "\n",
    "full_path = \"/home/joaovmrf/Documents/mestrado/SEED/SEED_EEG/SEED_EEG/ExtractedFeatures\"\n",
    "all_files = [each_file for each_file in glob(full_path+'/*.mat') if 'label.mat' not in each_file]\n",
    "all_files.sort()\n",
    "# all_files = glob.glob(full_path+\"*\")\n",
    "\n",
    "all_acc_results = []\n",
    "for cur_file in all_files: \n",
    "    #item = \"15_20130709.mat\"\n",
    "    #item = \"13_20140527.mat\"\n",
    "    item = os.path.basename(cur_file)\n",
    "    cur_user = item.split(\"_\")[0]\n",
    "    user_session = datetime.strptime(item.split(\"_\")[1][:-4],\"%Y%m%d\")\n",
    "    print(f\"- reading file: {item}\\n--user:{cur_user}, sessions: {user_session}\")\n",
    "\n",
    "    # cur_file = os.path.join(full_path, item)\n",
    "    all_data = sio.loadmat(cur_file)\n",
    "\n",
    "\n",
    "    train_data, test_data, train_label, test_label = generating_data(all_data, label_list, fn)\n",
    "\n",
    "    #train_data = preprocessing.scale(train_data)\n",
    "    #test_data = preprocessing.scale(test_data)\n",
    "\n",
    "    train_data_tensor = torch.from_numpy(train_data).to(torch.float)#.to(device)\n",
    "    test_data_tensor = torch.from_numpy(test_data).to(torch.float)#.to(device)\n",
    "    train_label_tensor = torch.from_numpy(train_label).to(torch.long)#.to(device)\n",
    "    test_label_tensor = torch.from_numpy(test_label).to(torch.long)#.to(device)\n",
    "\n",
    "\n",
    "    # define model\n",
    "    model = DGCNN(\n",
    "        in_channels=5, #5 frequencias\n",
    "        num_electrodes=62, #62 eletrodos\n",
    "        k_adj=K, #numero de layers - copiando do GMSS - na verdade no GMSS K=ordem de chebyshev\n",
    "        # out_channels=32, #copiando do GMSS, mas ainda nao entendi\n",
    "        out_channels=62,\n",
    "        num_classes=3\n",
    "    )\n",
    "\n",
    "    best_test_res = {\n",
    "        'acc':0,\n",
    "        'predict_label':None,\n",
    "        'trur_label':None\n",
    "    }\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                        lr=lr_dgcnn, weight_decay=weight_decay_dgcnn)\n",
    "    myloss = nn.CrossEntropyLoss()\n",
    "\n",
    "    for cur_epoch in range(epochs):\n",
    "        # ordem 1\n",
    "        # model.train() # como apontar  referencia aos dados de treino? R: E na definicao do modelo\n",
    "        # optimizer.zero_grad() #etapa comum em todos, zerar o gradiente.\n",
    "\n",
    "        # output = model(train_data_tensor)\n",
    "        # #TODO accuracy.\n",
    "        # #print(output)\n",
    "\n",
    "        # # import torch.nn.functional as F\n",
    "        # # loss_train = F.nll_loss(output, train_label)\n",
    "\n",
    "        # myloss = nn.CrossEntropyLoss()\n",
    "        # loss = myloss(output, train_label_tensor)\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "\n",
    "        # ordem 2\n",
    "        model.train() # como apontar  referencia aos dados de treino? R: E na definicao do modelo\n",
    "        output = model(train_data_tensor)\n",
    "        # STEP 10 - Calculate the loss function\n",
    "        loss = myloss(output, train_label_tensor)\n",
    "        \n",
    "        optimizer.zero_grad() #etapa comum em todos, zerar o gradiente.\n",
    "\n",
    "        #TODO accuracy.\n",
    "        #print(output)\n",
    "\n",
    "        # import torch.nn.functional as F\n",
    "        # loss_train = F.nll_loss(output, train_label)\n",
    "        # STEP 11 - Updating the Adj matrix\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Estou sentindo falta do coidgo de atualizacao dessa matriz\n",
    "\n",
    "        train_acc = torch.sum(torch.argmax(output, 1) == train_label_tensor) / train_data_tensor.shape[0]\n",
    "\n",
    "        print('Epoch : {} -- TrainLoss : {} -- TrainAcc : {}\\n'.format(cur_epoch, loss.cpu().data, train_acc.cpu().data))\n",
    "\n",
    "    model.eval()\n",
    "    test_output = model(test_data_tensor)\n",
    "    test_loss = myloss(test_output, test_label_tensor)\n",
    "    test_acc = torch.sum(torch.argmax(test_output, 1) == test_label_tensor) / test_data_tensor.shape[0]\n",
    "    print('Epoch : {} -- TestLoss : {} -- TestAcc : {}\\n'.format(cur_epoch, test_loss.cpu().data, test_acc.cpu().data))\n",
    "\n",
    "    # save the best results    \n",
    "    # if best_test_res['acc'] < test_acc.cpu().data:\n",
    "    best_test_res['acc'] = test_acc.cpu().data \n",
    "    best_test_res['loss'] = test_loss.cpu().data \n",
    "    best_test_res['predict_label'] = torch.argmax(test_output, 0).cpu().numpy()\n",
    "    best_test_res['true_label'] = test_label_tensor.cpu().numpy()\n",
    "    print('update res')\n",
    "\n",
    "    all_acc_results.append([item,best_test_res])\n",
    "\n",
    "    print(best_test_res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_acc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcnn_result_df = pd.DataFrame(all_acc_results)\n",
    "gcnn_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcnn_result_df[[\"user\", \"session\"]]  = pd.DataFrame(gcnn_result_df[0].str.split('_').to_list())\n",
    "gcnn_result_df[['acc','predict_label','trur_label','loss','true_label']] = pd.DataFrame(gcnn_result_df[1].to_list())\n",
    "gcnn_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcnn_result_df['acc'] = gcnn_result_df['acc'].apply(lambda x: x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eda_gcnn = gcnn_result_df[['user', 'session','acc', 'predict_label','trur_label','loss','true_label']].sort_values(['user', 'acc'], ascending=[False, False])\n",
    "eda_gcnn = gcnn_result_df[['user', 'session','acc']].sort_values(['user', 'acc'], ascending=[False, False])\n",
    "\n",
    "eda_gcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_gcnn.reset_index().to_csv(f\"GCNN_WITH_EVAL.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_gcnn.groupby(['user', 'session']).max()#.acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_gcnn.groupby(['user']).head(2).reset_index(drop=True)#.acc.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analisar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaovmrf/miniconda3/envs/ppget_env/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from model import DGCNN\n",
    "from sklearn import preprocessing\n",
    "from utils import generating_data\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- reading file: 13_20140603.mat\n",
      "--user:13, sessions: 2014-06-03 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t### TRAIN ###\n",
      "\t\tde_LDS1 - video 1 - (235, 62, 5) observacoes\n",
      "\t\tde_LDS2 - video 2 - (233, 62, 5) observacoes\n",
      "\t\tde_LDS3 - video 3 - (206, 62, 5) observacoes\n",
      "\t\tde_LDS4 - video 4 - (238, 62, 5) observacoes\n",
      "\t\tde_LDS5 - video 5 - (185, 62, 5) observacoes\n",
      "\t\tde_LDS6 - video 6 - (195, 62, 5) observacoes\n",
      "\t\tde_LDS7 - video 7 - (237, 62, 5) observacoes\n",
      "\t\tde_LDS8 - video 8 - (216, 62, 5) observacoes\n",
      "\t\tde_LDS9 - video 9 - (265, 62, 5) observacoes\n",
      "\t### TEST ###\n",
      "\t\tde_LDS10 - video 10 - (237, 62, 5) observacoes\n",
      "\t\tde_LDS11 - video 11 - (235, 62, 5) observacoes\n",
      "\t\tde_LDS12 - video 12 - (233, 62, 5) observacoes\n",
      "\t\tde_LDS13 - video 13 - (235, 62, 5) observacoes\n",
      "\t\tde_LDS14 - video 14 - (238, 62, 5) observacoes\n",
      "\t\tde_LDS15 - video 15 - (206, 62, 5) observacoes\n"
     ]
    }
   ],
   "source": [
    "fn = 'de_LDS'\n",
    "\n",
    "label_list = np.array([1,0,-1,-1,0,1,-1,0,1,1,0,-1,0,1,-1]) + 1 # -1 for \n",
    "\n",
    "full_path = \"/home/joaovmrf/Documents/mestrado/SEED/SEED_EEG/SEED_EEG/ExtractedFeatures\"\n",
    "all_files = [each_file for each_file in glob(full_path+'/*.mat') if 'label.mat' not in each_file]\n",
    "all_files.sort()\n",
    "# all_files = glob.glob(full_path+\"*\")\n",
    "\n",
    "\n",
    "# for cur_file in all_files: \n",
    "#item = \"15_20130709.mat\"\n",
    "#item = \"13_20140527.mat\"\n",
    "cur_file = all_files[10]\n",
    "item = os.path.basename(cur_file)\n",
    "cur_user = item.split(\"_\")[0]\n",
    "user_session = datetime.strptime(item.split(\"_\")[1][:-4],\"%Y%m%d\")\n",
    "print(f\"- reading file: {item}\\n--user:{cur_user}, sessions: {user_session}\")\n",
    "\n",
    "# cur_file = os.path.join(full_path, item)\n",
    "all_data = sio.loadmat(cur_file)\n",
    "\n",
    "\n",
    "train_data, test_data, train_label, test_label = generating_data(all_data, label_list, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "429040"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1384, 62, 5])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_tensor = torch.from_numpy(test_data).to(torch.float)#.to(device)\n",
    "test_data_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18.6900, 17.7714, 18.8810,  ..., 18.0466, 18.1342, 18.1445],\n",
       "        [18.6895, 17.7718, 18.8819,  ..., 18.0443, 18.1328, 18.1431],\n",
       "        [18.6886, 17.7711, 18.8821,  ..., 18.0420, 18.1315, 18.1419],\n",
       "        ...,\n",
       "        [18.3036, 17.4334, 18.2986,  ..., 18.3583, 18.2486, 18.2527],\n",
       "        [18.3007, 17.4315, 18.2951,  ..., 18.3586, 18.2484, 18.2525],\n",
       "        [18.2992, 17.4308, 18.2932,  ..., 18.3590, 18.2481, 18.2521]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pegando apenas o primeiro video (236), todos os canais, a ultima frequencia\n",
    "test_data_tensor[:236,:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([236])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pegando apenas o primeiro video (236), canal 1, frequencia delta\n",
    "test_data_tensor[:236,0,0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mudando eixo para entneder matriz de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1384, 62, 5)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 5, 1384)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_swapped = np.swapaxes(test_data, 0, 1)\n",
    "test_data_swapped = np.swapaxes(test_data_swapped, 1, 2)\n",
    "test_data_swapped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_swapped_tensor = torch.from_numpy(test_data_swapped).to(torch.float)#.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([62, 5, 1384])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_swapped_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([62, 1384])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pegando todos os 62 canais, apenas frequencia delta \n",
    "test_data_swapped_tensor[:,0,:].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "429040"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppget_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
